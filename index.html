<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion-Based Egyptian Music Player</title>
    <style>
        :root {
            --primary-color: #1e88e5;
            --secondary-color: #f5f5f5;
            --accent-color: #ff9800;
            --dark-color: #333;
            --light-color: #fff;
            --border-radius: 8px;
            --spacing: 20px;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background-color: #f0f2f5;
            color: var(--dark-color);
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: var(--spacing);
        }

        .header {
            background-color: var(--light-color);
            padding: 15px var(--spacing);
            border-radius: var(--border-radius);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            margin-bottom: var(--spacing);
            text-align: center;
        }

        .title {
            font-size: 28px;
            font-weight: bold;
            color: var(--primary-color);
        }

        .main-content {
            display: flex;
            flex-wrap: wrap;
            gap: var(--spacing);
        }

        .card {
            background-color: var(--light-color);
            border-radius: var(--border-radius);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            padding: var(--spacing);
            flex: 1;
            min-width: 300px;
        }

        .card-title {
            font-size: 18px;
            font-weight: bold;
            margin-bottom: 15px;
            color: var(--primary-color);
        }

        .camera-feed {
            width: 100%;
            height: 320px;
            background-color: #eee;
            border-radius: var(--border-radius);
            display: flex;
            justify-content: center;
            align-items: center;
            margin-bottom: 15px;
            overflow: hidden;
        }

        .camera-feed video, 
        .camera-feed canvas {
            max-width: 100%;
            max-height: 100%;
        }

        .info-row {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
        }

        .info-label {
            width: 120px;
            font-weight: bold;
        }

        .info-value {
            flex: 1;
        }

        progress {
            width: 100%;
            height: 12px;
            border-radius: 6px;
        }

        progress::-webkit-progress-bar {
            background-color: #eee;
            border-radius: 6px;
        }

        progress::-webkit-progress-value {
            background-color: var(--primary-color);
            border-radius: 6px;
        }

        .button-group {
            display: flex;
            gap: 10px;
            margin-top: 20px;
        }

        .button {
            flex: 1;
            padding: 10px;
            background-color: var(--primary-color);
            color: var(--light-color);
            border: none;
            border-radius: var(--border-radius);
            cursor: pointer;
            font-weight: bold;
            transition: background-color 0.2s;
        }

        .button:hover {
            background-color: #1565c0;
        }

        .button.stop {
            background-color: #d32f2f;
        }

        .button.stop:hover {
            background-color: #b71c1c;
        }

        .status-bar {
            background-color: var(--light-color);
            padding: 10px var(--spacing);
            border-radius: var(--border-radius);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            margin-top: var(--spacing);
        }

        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 100;
            justify-content: center;
            align-items: center;
        }

        .modal-content {
            background-color: var(--light-color);
            border-radius: var(--border-radius);
            box-shadow: 0 2px 15px rgba(0, 0, 0, 0.2);
            padding: var(--spacing);
            width: 90%;
            max-width: 600px;
            max-height: 90vh;
            overflow-y: auto;
        }

        .modal-title {
            font-size: 22px;
            margin-bottom: 15px;
            color: var(--primary-color);
            text-align: center;
        }

        .modal-body {
            margin-bottom: 20px;
        }

        .emotion-box {
            display: inline-block;
            padding: 8px 12px;
            border-radius: 20px;
            background-color: var(--primary-color);
            color: white;
            margin-right: 10px;
            margin-bottom: 10px;
        }

        .slider-container {
            width: 100%;
        }

        .slider {
            width: 100%;
            height: 12px;
            border-radius: 6px;
            -webkit-appearance: none;
            appearance: none;
            outline: none;
            background: #ddd;
            transition: opacity 0.2s;
        }

        .slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: var(--primary-color);
            cursor: pointer;
        }

        .center-text {
            text-align: center;
            margin: 10px 0;
        }

        .music-info {
            padding: 15px;
            background-color: #f5f5f5;
            border-radius: var(--border-radius);
            margin-top: 15px;
        }

        .face-box {
            position: absolute;
            border: 3px solid #4CAF50;
            background-color: rgba(76, 175, 80, 0.1);
        }

        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="title">Emotion-Based Egyptian Music Player</div>
        </div>

        <div class="main-content">
            <div class="card">
                <div class="card-title">Emotion Detection</div>
                <div class="camera-feed">
                    <video id="video" autoplay muted></video>
                    <canvas id="canvas" style="display:none;"></canvas>
                </div>
            </div>

            <div class="card">
                <div class="card-title">Controls & Status</div>
                
                <div class="info-row">
                    <div class="info-label">Current Emotion:</div>
                    <div class="info-value" id="emotion-value">None</div>
                </div>
                
                <div class="info-row">
                    <div class="info-label">Confidence:</div>
                    <div class="info-value">
                        <progress id="confidence-bar" value="0" max="1"></progress>
                    </div>
                </div>
                
                <div class="info-row">
                    <div class="info-label">Current Music:</div>
                    <div class="info-value" id="music-value">None</div>
                </div>
                
                <div class="info-row">
                    <div class="info-label">Volume:</div>
                    <div class="info-value">
                        <div class="slider-container">
                            <input type="range" min="0" max="1" value="0.7" step="0.01" class="slider" id="volume-slider">
                        </div>
                    </div>
                </div>

                <div class="music-info">
                    <p>Music will play based on detected emotions:</p>
                    <div class="emotion-box">Happy</div>
                    <div class="emotion-box">Sad</div>
                    <div class="emotion-box">Angry</div>
                    <div class="emotion-box">Surprised</div>
                    <div class="emotion-box">Neutral</div>
                </div>
                
                <div class="button-group">
                    <button class="button" id="start-btn">Start</button>
                    <button class="button stop" id="stop-btn">Stop</button>
                </div>
            </div>
        </div>

        <div class="status-bar">
            <div id="status">Ready to start. Click 'Start' to begin.</div>
        </div>
    </div>

    <!-- Setup Instructions Modal -->
    <div class="modal" id="setup-modal">
        <div class="modal-content">
            <div class="modal-title">ðŸŽµ Music Setup Required ðŸŽµ</div>
            <div class="modal-body">
                <p>No music files were found in the data directory!</p>
                <p>Please add Egyptian music files to the following directories:</p>
                
                <ul style="margin: 15px 0 15px 20px;">
                    <li>data/music/happy/</li>
                    <li>data/music/sad/</li>
                    <li>data/music/neutral/</li>
                    <li>data/music/angry/</li>
                    <li>data/music/surprised/</li>
                </ul>
                
                <p>Add MP3, WAV, or OGG files to these directories based on their emotional content.</p>
                <p>For example, put upbeat songs in the 'happy' folder and melancholic ones in the 'sad' folder.</p>
                <p>Once you've added the music files, restart the application.</p>
                
                <div class="center-text">
                    <button class="button" id="setup-ok-btn">OK</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Sample Egyptian music data (simulating the music files)
        const musicData = {
            happy: [
                { name: "Hakuna Matata - Happy Song.mp3", path: "" },
                { name: "happy.mp3", path: "https://www.youtube.com/watch?v=2bEQvnP4D5o" }
            ],
            sad: [
                { name: "sad.mp3", path: "/data/music/sad/sad.mp3" }
            ],
            angry: [
                { name: "angry.mp3", path: "/data/music/angry/angry.mp3" }
            ],
            surprised: [
                { name: "surprised.mp3", path: "/data/music/surprised/surprised.mp3" }
            ],
            neutral: [
                { name: "neutral.mp3", path: "/data/music/neutral/neutral.mp3" } 
            ]
        };

        // Emotion mapping
        const emotionMap = {
            angry: 'angry',
            disgust: 'angry',
            fear: 'sad',
            happy: 'happy',
            sad: 'sad',
            surprised: 'surprised',
            neutral: 'neutral'
        };

        // DOM elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const emotionValue = document.getElementById('emotion-value');
        const confidenceBar = document.getElementById('confidence-bar');
        const musicValue = document.getElementById('music-value');
        const volumeSlider = document.getElementById('volume-slider');
        const startBtn = document.getElementById('start-btn');
        const stopBtn = document.getElementById('stop-btn');
        const statusElem = document.getElementById('status');
        const setupModal = document.getElementById('setup-modal');
        const setupOkBtn = document.getElementById('setup-ok-btn');

        // Canvas context
        const ctx = canvas.getContext('2d');

        // Audio element for music playback
        const audioPlayer = new Audio();
        audioPlayer.volume = 0.7;
        audioPlayer.loop = true;

        // App state
        let isRunning = false;
        let currentEmotion = null;
        let detectionInterval = null;
        let faceDetector = null;

        // Simulated face detection results for demo purposes 
        // (since browser API can't really detect emotions)
        const emotions = ['happy', 'sad', 'angry', 'surprised', 'neutral'];
        let detectedFaces = [];

        // Initialize the app
        function init() {
            // Show setup instructions (simulating music file check)
            setupModal.style.display = 'flex';

            // Initialize volume slider
            volumeSlider.addEventListener('input', (e) => {
                audioPlayer.volume = e.target.value;
            });

            // Setup button event listeners
            startBtn.addEventListener('click', startDetection);
            stopBtn.addEventListener('click', stopDetection);
            setupOkBtn.addEventListener('click', () => {
                setupModal.style.display = 'none';
            });

            // Check if faceDetector is available
            if ('FaceDetector' in window) {
                // Use browser's FaceDetector API if available
                faceDetector = new FaceDetector();
                updateStatus("FaceDetector API is supported.");
            } else {
                updateStatus("FaceDetector API is not supported. Using simulated detection.");
                // We'll use simulated face detection
            }
        }

        // Start emotion detection
        function startDetection() {
            if (isRunning) return;
            
            updateStatus("Starting camera...");
            
            // Access webcam
            navigator.mediaDevices.getUserMedia({ video: true })
                .then((stream) => {
                    video.srcObject = stream;
                    isRunning = true;
                    
                    // Set canvas dimensions based on video stream
                    setTimeout(() => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                    }, 500);
                    
                    // Start detection loop
                    detectionInterval = setInterval(detectEmotion, 1000);
                    updateStatus("Camera started. Detecting emotions...");
                })
                .catch((err) => {
                    updateStatus(`Error accessing camera: ${err.message}`);
                    console.error("Error accessing camera:", err);
                });
        }

        // Stop emotion detection
        function stopDetection() {
            if (!isRunning) return;
            
            clearInterval(detectionInterval);
            
            // Stop camera
            if (video.srcObject) {
                const tracks = video.srcObject.getTracks();
                tracks.forEach(track => track.stop());
                video.srcObject = null;
            }
            
            // Stop music
            audioPlayer.pause();
            
            // Reset UI
            isRunning = false;
            emotionValue.textContent = "None";
            musicValue.textContent = "None";
            confidenceBar.value = 0;
            
            updateStatus("Stopped");
        }

        // Detect emotion from video feed
        function detectEmotion() {
            if (!isRunning) return;
            
            // Draw current video frame to canvas
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            // Simulated emotion detection (in a real app, this would use ML models)
            simulateFaceDetection();
        }

        // Simulate face detection and emotion recognition
        function simulateFaceDetection() {
            // For demo: 80% chance to detect a face
            if (Math.random() > 0.2) {
                // Generate random face box (in a real app, this would come from ML detection)
                const centerX = canvas.width * (0.4 + Math.random() * 0.2);
                const centerY = canvas.height * (0.4 + Math.random() * 0.2);
                const size = Math.min(canvas.width, canvas.height) * (0.2 + Math.random() * 0.1);
                
                // Draw face box on canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                ctx.strokeStyle = '#4CAF50';
                ctx.lineWidth = 3;
                ctx.strokeRect(centerX - size/2, centerY - size/2, size, size);
                
                // Select random emotion with some persistence
                // (so it doesn't change every time)
                if (!currentEmotion || Math.random() < 0.3) {
                    currentEmotion = emotions[Math.floor(Math.random() * emotions.length)];
                }
                
                // Calculate confidence (random but biased toward high values)
                const confidence = 0.5 + Math.random() * 0.5;
                
                // Update UI
                updateDetectedEmotion(currentEmotion, confidence);
            } else {
                // No face detected
                emotionValue.textContent = "No Face";
                confidenceBar.value = 0;
                // We don't change music when no face is detected
            }
        }

        // Update UI with detected emotion and play corresponding music
        function updateDetectedEmotion(emotion, confidence) {
            // Update UI
            emotionValue.textContent = emotion.charAt(0).toUpperCase() + emotion.slice(1);
            confidenceBar.value = confidence;
            
            // Play corresponding music if confidence is high enough
            if (confidence > 0.4) {
                const mappedEmotion = emotionMap[emotion] || 'neutral';
                const musicList = musicData[mappedEmotion];
                
                if (musicList && musicList.length > 0) {
                    // Select random music for this emotion
                    const randomMusic = musicList[Math.floor(Math.random() * musicList.length)];
                    
                    // Only change music if emotion changed
                    if (audioPlayer.getAttribute('data-emotion') !== mappedEmotion) {
                        updateStatus(`Detected ${emotion} emotion, changing music...`);
                        
                        // In a real app, we would set the actual audio source
                        audioPlayer.src = randomMusic.path;
                        
                        // For demo, we just update the UI
                        audioPlayer.setAttribute('data-emotion', mappedEmotion);
                        musicValue.textContent = randomMusic.name;
                        
                        // Simulate starting playback
                        if (audioPlayer.paused) {
                            audioPlayer.play().catch(err => console.error("Error playing audio:", err));
                        }
                    }
                }
            }
        }

        // Update status message
        function updateStatus(message) {
            statusElem.textContent = message;
        }

        // Initialize app when DOM is loaded
        document.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>